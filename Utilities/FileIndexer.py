import glob2
import csv
import hashlib
import os
import pefile
import entropy
import argparse
import magic
import time
import string

field_names = ['sha256', 'strings', 'imports', 'size', 'signed', 'good_file', 'entropy']


def get_file_size(FilePath):
    return os.path.getsize(FilePath)


def get_file_signatures(FilePath):
 
    try:
        pe = pefile.PE(FilePath)
 
        address = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_SECURITY']].VirtualAddress
        size = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_SECURITY']].Size
        if address == 0:
            return 0
        return 1
    except:
        return -1


def get_strings(filename, min_length):
    file_data = open(filename, 'rb')

    strings_list = []

    current = ''
    for character in file_data.read():
        if character in string.printable:
            current += character
        else:
            if len(current) > min_length:
                strings_list.append(current)

            current = ''

    return strings_list


def get_md5_of_file(FilePath):
    return hashlib.md5(FilePath).hexdigest()


def get_sha256_of_file(FilePath):
    return hashlib.sha256(FilePath).hexdigest()


def get_filename_from_path(FilePath):
    FileSplitPath = FilePath.split("\\")
    return FileSplitPath[-1]


def get_file_path(FilePath):
    FileSplitPath = FilePath.split("\\")
    seq = "\\"
    return seq.join(FileSplitPath[0:len(FileSplitPath) - 1])


def get_import_table_entries(FilePath):
    imports = []

    try:
        pe = pefile.PE(FilePath)

        for entry in pe.DIRECTORY_ENTRY_IMPORT:
            # print entry.dll
            for imp in entry.imports:
                imports.append(imp.name)
    except:
        # print "Error: ", filepath
        imports.append("Error")
    return imports


def get_entropy_of_file(FilePath):
    file_read = open(FilePath, 'r')
    file_data = file_read.read()

    entropy_file = entropy.shannon_entropy(file_data)
    file_read.close()
    return entropy_file


def get_type_of_file(FilePath):
    magic_type = magic.from_file(FilePath)
    
    if 'DLL' in magic_type:
        return 0
    else:
        return 1


def is_pefile(FilePath):
    is_PE = 0
    file_handle = open(FilePath, "rb")

    if file_handle.read(2) == "MZ":
        is_PE = 1
    file_handle.close()

    return is_PE


def write_stats_to_csv(csv_file, path, good_file, all_pe):

    files = glob2.glob(path + "/*")
    writer = csv.DictWriter(csv_file, field_names)

    sha256_dict = {}
    total = 0
    count = 0
    duplicates = 0
    for filename in files:
        total += 1
        if all_pe == 1 or is_pefile(filename):
            count += 1
            size = get_file_size(filename)
            imports = get_import_table_entries(filename)
            sha256 = get_sha256_of_file(filename)
            signed = get_file_signatures(filename)
            entropy = get_entropy_of_file(filename)
            strings = get_strings(filename, 8)
            #file_type = get_type_of_file(filename)
            if sha256 not in sha256_dict:
                writer.writerow(
                    {'sha256': sha256, 'strings': strings, 'imports': imports, 'size': size, 'signed': signed, 'good_file': good_file,
                     'entropy': entropy})
                sha256_dict[sha256] = 1
            else:
                duplicates += 1
            if count % 100 == 0:
                print "Got through: ", count
        if total % 100 == 0:
	    print "Total Files Processed: ", total
    

    print "\nDone: %s" % path
    print "Duplicates: %d\n" % duplicates


def main():
    parser = argparse.ArgumentParser(description="File Indexer for Blue Sentry")
    parser.add_argument("--output_file", help="File that the data is output to in csv form", required=True)
    parser.add_argument("--input_directory", help="Directory for which the parser will run through for "
                                                  "executables and DLLs", required=True)
    parser.add_argument("--good_file", help="An indication whether or not the files in the input directory are known "
                                            "good or bad. 0 for bad, 1 for good", required=True)
    parser.add_argument("--all_pe", help="Indication whether all the files in the current directory are known to be PE files", default=0)

    args = parser.parse_args()

    #csv_file = open('data_working.csv', 'a+')
    write_header = True
    if os.path.isfile(args.output_file):
        print "File!"
        write_header = False

    csv_file = open(args.output_file, 'a+')

    writer = csv.DictWriter(csv_file, field_names)

    if write_header:
        writer.writeheader()

    start_time = time.time()

    write_stats_to_csv(csv_file, args.input_directory, int(args.good_file), int(args.all_pe))
    #write_stats_to_csv(csv_file, '/home/processing/Desktop/ML/ExeFolder/*', 1)
    #write_stats_to_csv(csv_file, '/home/processing/Desktop/ML/KnownBad/VirusShare_PE32_Win_20150129/*', 0)
    end_time = time.time()
    total_time = end_time - start_time
    print "Total Time: ", str(total_time)
    csv_file.close()

if __name__ == "__main__":
    main()
