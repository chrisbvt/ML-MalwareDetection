import itertools
import numpy as np
import pandas as pd
import joblib
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
import argparse

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix


def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')


def main():

    parser = argparse.ArgumentParser(description="File Indexer for Blue Sentry")
    parser.add_argument("--data_file", help="File that the data is output to in csv form", required=True)
    parser.add_argument("--imports_file", help="The file which holds the imports prased via the ImportsIndexer", required=True)
    parser.add_argument("--classifier", help="The file containing the saved classifier", required=True)
    args = parser.parse_args()
    # import some data to play with
    data_orig = pd.read_csv(args.data_file)
    print "Data loaded!"

    #display(data.describe)

    data = data_orig.sample(frac=1, random_state=40)

    data_features = data['good_file']
    data = data.drop(['good_file'], axis=1)
    #data = data.drop(['file_type'], axis=1)
    data = data.drop(['sha256'], axis=1)
    data_imports = data['imports']
    data = data.drop(['imports'], axis=1)

    text_encoding = open(args.imports_file, 'r').read()

    encoder = CountVectorizer()
    encoder = encoder.fit(text_encoding.split())
    data_imports_encoded = encoder.transform(data_imports)
    testing_size = .2

    x_train_nn, x_test_nn, y_train_nn, y_test_nn = train_test_split(data_imports_encoded, data_features, test_size=testing_size, random_state=65)

    # Run classifier, using a model that is too regularized (C too low) to see
    # the impact on the results
    classifier = joblib.load(args.classifier)
    y_pred = classifier.predict(x_test_nn)


    # Compute confusion matrix
    cnf_matrix = confusion_matrix(y_test_nn, y_pred)
    np.set_printoptions(precision=4)

    # Plot non-normalized confusion matrix
    plt.figure()
    plot_confusion_matrix(cnf_matrix, classes=['bad_file', 'good_file'],
                          title='Confusion matrix, without normalization')

    # Plot normalized confusion matrix
    plt.figure()
    plot_confusion_matrix(cnf_matrix, classes=['bad_file', 'good_file'], normalize=True,
                          title='Normalized confusion matrix')

    plt.show()

if __name__ == "__main__":
    main()
